\documentclass[../paper.tex]{subfiles}

% Document
\begin{document}
    Last but not least, we will look at machine learning models.
    These are models that are already trained on a lot of data, and can then be used to predict the weather.
    So the hassle of training is already done for us (also in the case of APIs).

    \subsubsection{How does it work?}

    \subsubsection{ClimaX}
        \hfill\\
        ClimaX is the first foundation model designed to perform a wide variety of weather and climate modeling tasks.
        For weather, these tasks include standard forecasting tasks of relevant weather variables like temperature,
        humidity, etc.
        with various lead-times at various resolutions, both globally and regionally.
        For climate, ClimaX can help to make better long-term projections,
        or to downscale lower resolution model outputs to higher resolutions.
        At its core, ClimaX is a multidimensional image-to-image translation architecture based on Vision Transformers
        (ViT).
        ViT-based architectures are especially well suited for modeling weather and climate phenomena
        since they naturally tokenize the spatial nature of multiscale data akin to different spatial-temporal inputs.
        Additionally,
        they offer the opportunity to extend tokenization towards a wide range of multichannel features\cite{d1}.
        \\\\
        \textbf{Results highlights}:\\
            Forecasting the future values of key weather variables at different temporal horizons is critical
            to ensuring the safety of communities and infrastructure around the world.
            ERA5 is the latest climate reanalysis produced by ECMWF,
            providing hourly data on many atmospheric,
            land-surface and sea-state parameters together with estimates of uncertainty\cite{d2}.
            ERA5 reanalysis data from the ECMWF underlies as the key source of data for training
            and evaluating machine learning models on this task with performance of Operation
            IFS being the current state-of-the art numerical weather prediction baseline.
            ClimaX when fine-tuned on the same ERA5 data,
            even at medium resolutions 1.40625\textdegree already performs comparably,
            if not better than IFS on short and medium-range predictions,
            while being substantially better at longer horizon predictions\cite{d1}.
            \begin{figure}[h]
            \centering
            \includegraphics[width=0.5\textwidth]{../photos/climax_ifs}
            \caption{ClimaX vs IFS on global forecasting of key weather variables at different lead time horizons}
            \label{fig:climax-vs-ifs}
            \end{figure}\\\\\\
            In the graphs above,
            we compare the performance of ClimaX vs IFS on global forecasting of key weather variables at different lead time horizons:
            \begin{itemize}
                \item Temperature T2M (2m above ground)
                \item Temperature T850 (850hPa)
                \item Wind speed U10M (10m above ground)
                \item Geo-potential height Z500 (500hPa)
            \end{itemize}
            In short, we can see that ClimaX performs somewhat comparably to IFS on short and medium-range predictions,
            while being substantially better at longer horizon predictions (in most of these graphs, 14 days and above).\\
    \subsubsection{GraphCast}
        GraphCast is a machine learning-based method developed by Google DeepMind for medium-range global weather forecasting.
        It is an autoregressive model based on graph neural networks and a novel high-resolution multiscale mesh representation.
        It is a mesh representation used to represent the Earth's surface and atmosphere.
        The mesh is a grid of points that are connected by lines to form triangles.
        The mesh is multiscale, meaning that it has different resolutions at different levels.
        The mesh is high-resolution, meaning that it has a high density of points, which allows for more accurate predictions.
        GraphCast is trained on historical weather data from the European Centre for Medium-Range Weather Forecasts (ECMWF)'s ERA5 reanalysis archive\cite{e1}.
        \\\\
        It starts with the current state of Earth's weather and data about the weather six hours ago.
        Then, it makes a prediction about what the weather will look like six hours from now.\\
        GraphCast then feeds those predictions back into the model, performs the same calculation, and spits out longer-term forecasts\cite{e1}.\\
        \begin{figure}[htbp]
            \centerline{\includegraphics[width=0.4\textwidth]{../photos/multimesh_graphcast}}
            \caption{Steps of GraphCast}
            \label{fig:multimesh-graphcast}
        \end{figure}\\
        GraphCast's multiscale mesh representation. \\
        A) First, we insert the data into the model.
        B) Then we perform GraphCast to predict data, we feed this data back into the model.
        C) We perform GraphCast again to predict data, we feed this data back into the model and do this repeatedly.
        D) The encoder component maps local regions of the input (the green boxes) into nodes of the multi-mesh graph representation.
        E) The processor component performs a series of graph neural network (GNN) message passing steps to update the node features.
        F) The decoder component maps the updated node features back to the output (the purple boxes).
        G) The multi-mesh is a set of icosahedral meshes of increasing resolution, from the base mesh ($M^0$, 12 nodes) to the finest resolution ($M^6$ , 40, 962 nodes), which has uniform resolution across the globe.
        Each node belongs to a particular mesh resolution, and is connected to all neighboring nodes at the same resolution, as well as higher resolutions.
        The learned message-passing over the different meshes' edges happens simultaneously, so that each node is updated by all of its incoming edges.
        \\\\
        The package contains example code to run and train GraphCast.
        It also provides three pretrained models: GraphCast, the high-resolution model used in the GraphCast paper (0.25 degree resolution, 37 pressure levels),
        trained on ERA5 data from 1979 to 2017, Grap\_Cast\_small, a smaller, low-resolution version of GraphCast (1 degree resolution,
        13 pressure levels, and a smaller mesh), trained on ERA5 data from 1979 to 2015, useful to run a model with lower memory and compute constraints,
        GraphCast\_operational, a high-resolution model (0.25 degree resolution, 13 pressure levels) pretrained on ERA5 data from 1979 to 2017
        and fine-tuned on HRES data from 2016 to 2021\cite{e2}.
    \subsubsection{ClimaX vs GraphCast}
    \hfill\\
    ClimaX and GraphCast are both tools used in the field of weather and climate modeling, but they serve different purposes and have different features.
    \\
    ClimaX is a foundation model designed for a wide variety of weather and climate modeling tasks.
    It is based on Vision Transformers (ViT) and is capable of performing standard forecasting tasks of relevant weather variables like temperature, humidity, etc.
    with various lead-times at various resolutions, both globally and regionally.
    It can also help to make better long-term projections, or to downscale lower resolution model outputs to higher resolutions.

    On the other hand, GraphCast is a machine learning-based method developed by Google DeepMind for medium-range global weather forecasting.
    It uses graph neural networks and a novel high-resolution multiscale mesh representation to make weather predictions.
    It is an autoregressive model that starts with the current state of Earth's weather and data about the weather six hours ago, then makes a prediction about what the weather will look like six hours from now.
    This process is repeated to generate longer-term forecasts.

In summary, while ClimaX is a foundation model used for a wide range of weather and climate modeling tasks, GraphCast is a machine learning-based method specifically designed for medium-range global weather forecasting.
\subsubsection{How can they be used?}
    For our project, we can use these pre-trained models to make accurate predictions about the weather.
    We can use them to predict the weather for the next few days, weeks, or even months.
    The predictions that will be useful for our project are: precipitation, temperature, wind speed, and humidity.
\subsubsection{Advantages of ML}
    There are many advantages to using a pre-trained model, but we will discuss the advantages relevant to our project.
    \begin{itemize}
        \item \textbf{Versatility:} ClimaX is designed to perform a wide variety of weather and climate modeling tasks.
        It can help make better long-term projections or downscale lower resolution model outputs to higher resolution~\cite{d1}.
        \item \textbf{Fine-tuning:} The model can be fine-tuned to address a wide variety of climate and weather tasks, including those that involve atmospheric variables and spatio-temporal granularity unseen during pretraining~\cite{d1}
        \item \textbf{Speed and Accuracy:} GraphCast delivers 10-day weather predictions at unprecedented accuracy in under one minute.
        It predicts weather conditions up to 10 days in advance more accurately and much faster than the industry gold-standard weather simulation system~\cite{e5}.
    \end{itemize}
\subsubsection{Disadvantages of ML}
    Alongside the advantages, there are also disadvantages to using a pre-trained model, specifically ClimaX and GraphCast.
    \begin{itemize}
        \item \textbf{Limitations in Prediction:} While ClimaX outperforms baselines in terms of temperature prediction, it underperforms in terms of precipitation prediction~\cite{d3}.
        \item \textbf{Data Dependency:}
        GraphCast is trained on decades of historical weather data
        to learn a model of the cause and effect relationships that govern how Earth's
        weather evolves.
        This means its performance is heavily dependent on the quality and comprehensiveness of the training data~\cite{e5}.
    \end{itemize}

\end{document}